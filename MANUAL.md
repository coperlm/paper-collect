# Paper Collector - å®Œæ•´ä½¿ç”¨æ‰‹å†Œ

> æœ¬æ‰‹å†Œæä¾›æ‰€æœ‰åŠŸèƒ½çš„è¯¦ç»†è¯´æ˜ï¼Œé€‚åˆæ·±åº¦ä½¿ç”¨å’ŒäºŒæ¬¡å¼€å‘

---

## ğŸ“‘ ç›®å½•

- [å®‰è£…ä¸é…ç½®](#å®‰è£…ä¸é…ç½®)
- [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
- [æ•°æ®è®¿é—®](#æ•°æ®è®¿é—®)
- [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
- [é…ç½®è¯¦è§£](#é…ç½®è¯¦è§£)
- [APIå‚è€ƒ](#apiå‚è€ƒ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å¼€å‘æŒ‡å—](#å¼€å‘æŒ‡å—)

---

## å®‰è£…ä¸é…ç½®

### ç³»ç»Ÿè¦æ±‚

- Python 3.7+
- Windows/Linux/macOS
- ç½‘ç»œè¿æ¥ï¼ˆè®¿é—®DBLPå’ŒSemantic Scholarï¼‰

### å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
git clone https://github.com/coperlm/paper-collect.git
cd paper-collect

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. éªŒè¯å®‰è£…
python main.py --help
```

### ä¾èµ–è¯´æ˜

- `requests` - HTTPè¯·æ±‚
- `beautifulsoup4` + `lxml` - HTMLè§£æ
- `pyyaml` - é…ç½®æ–‡ä»¶è§£æ
- `tqdm` - è¿›åº¦æ¡æ˜¾ç¤º
- `selenium` - ï¼ˆå¯é€‰ï¼‰ç”¨äºå¤æ‚ç½‘é¡µçˆ¬å–

---

## æ ¸å¿ƒåŠŸèƒ½

### 1. æ”¶é›†è®ºæ–‡å…ƒæ•°æ®

ä»DBLPè·å–è®ºæ–‡çš„åŸºæœ¬ä¿¡æ¯ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
# æ”¶é›†æ‰€æœ‰é…ç½®çš„ä¼šè®®
python main.py collect

# æ”¶é›†ç‰¹å®šä¼šè®®
python main.py collect --conferences crypto

# æ”¶é›†ç‰¹å®šå¹´ä»½
python main.py collect --years 2024

# ç»„åˆæ¡ä»¶
python main.py collect --conferences crypto asiacrypt --years 2023 2024
```

#### å·¥ä½œåŸç†

1. è¯»å– `config/conferences.yaml` ä¸­çš„ä¼šè®®é…ç½®
2. é€šè¿‡DBLP APIæŸ¥è¯¢è®ºæ–‡
3. è§£æè¿”å›çš„JSONæ•°æ®
4. å­˜å‚¨åˆ°SQLiteæ•°æ®åº“

#### æ•°æ®å­—æ®µ

- `title` - è®ºæ–‡æ ‡é¢˜
- `authors` - ä½œè€…åˆ—è¡¨ï¼ˆåˆ†å·åˆ†éš”ï¼‰
- `year` - å‘è¡¨å¹´ä»½
- `conference` - ä¼šè®®åç§°
- `url` - DBLPé“¾æ¥
- `doi` - DOIæ ‡è¯†
- `dblp_key` - DBLPå”¯ä¸€é”®

### 2. è·å–è®ºæ–‡æ‘˜è¦

é€šè¿‡Semantic Scholar APIè¡¥å……æ‘˜è¦ä¿¡æ¯ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
# ä¸ºæ‰€æœ‰è®ºæ–‡è·å–æ‘˜è¦
python main.py enrich

# é™åˆ¶æ•°é‡
python main.py enrich --limit 10

# ç‰¹å®šä¼šè®®
python main.py enrich --conference "CRYPTO" --year 2024
```

#### æ™ºèƒ½è·å–ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨æ™ºèƒ½è„šæœ¬ï¼Œè‡ªåŠ¨è¿‡æ»¤ä¼šè®®æ–‡é›†
python enrich_smart.py 50
```

**æ™ºèƒ½è¿‡æ»¤è§„åˆ™ï¼š**
- æ’é™¤åŒ…å« "Proceedings", "Conference" çš„æ ‡é¢˜
- æ’é™¤ISBNæ ¼å¼çš„DOI
- åªå¤„ç†çœŸæ­£çš„å•ç¯‡è®ºæ–‡

#### å·¥ä½œåŸç†

1. ä»æ•°æ®åº“è¯»å–ç¼ºå°‘æ‘˜è¦çš„è®ºæ–‡
2. ä¼˜å…ˆä½¿ç”¨DOIæŸ¥è¯¢Semantic Scholar
3. DOIå¤±è´¥åˆ™ä½¿ç”¨æ ‡é¢˜æœç´¢
4. æ›´æ–°æ•°æ®åº“ä¸­çš„abstractå­—æ®µ
5. é™„åŠ å¼•ç”¨æ•°å’Œå‘è¡¨æ—¥æœŸåˆ°noteså­—æ®µ

#### é€Ÿç‡é™åˆ¶

- Semantic Scholaré™åˆ¶ï¼šæ¯ç§’1æ¬¡è¯·æ±‚
- æœ¬å·¥å…·è®¾ç½®ï¼šæ¯æ¬¡é—´éš”2ç§’
- å»ºè®®åˆ†æ‰¹å¤„ç†ï¼Œé¿å…ä¸€æ¬¡å¤„ç†å¤ªå¤š

### 3. ä¸‹è½½PDFæ–‡ä»¶

æ‰¹é‡ä¸‹è½½è®ºæ–‡PDFæ–‡ä»¶ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
# ä¸‹è½½æ‰€æœ‰å¾…ä¸‹è½½çš„PDF
python main.py download

# é™åˆ¶ä¸‹è½½æ•°é‡
python main.py download --limit 10

# ä¸‹è½½ç‰¹å®šä¼šè®®
python main.py download --conference "CRYPTO"

# ä¸‹è½½ç‰¹å®šå¹´ä»½
python main.py download --conference "CRYPTO" --year 2024
```

#### é‡è¯•å¤±è´¥çš„ä¸‹è½½

```bash
python main.py retry
```

#### å­˜å‚¨ç»“æ„

```
data/pdfs/
â”œâ”€â”€ CRYPTO/
â”‚   â”œâ”€â”€ 2024/
â”‚   â”‚   â”œâ”€â”€ paper1.pdf
â”‚   â”‚   â””â”€â”€ paper2.pdf
â”‚   â””â”€â”€ 2023/
â”œâ”€â”€ ASIACRYPT/
â””â”€â”€ ...
```

#### ä¸‹è½½çŠ¶æ€

- `pending` - å¾…ä¸‹è½½
- `downloading` - ä¸‹è½½ä¸­
- `completed` - å·²å®Œæˆ
- `failed` - å¤±è´¥

### 4. å¯¼å‡ºJSONæ•°æ®

å°†æ•°æ®åº“å†…å®¹å¯¼å‡ºä¸ºJSONæ ¼å¼ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
# è‡ªåŠ¨å¯¼å‡ºæ‰€æœ‰æ ¼å¼
python main.py export

# æŒ‡å®šå¯¼å‡ºæ¨¡å¼
python main.py export --mode all         # å•ä¸ªå®Œæ•´æ–‡ä»¶
python main.py export --mode conference  # æŒ‰ä¼šè®®åˆ†æ–‡ä»¶
python main.py export --mode year        # æŒ‰ä¼šè®®å’Œå¹´ä»½åˆ†æ–‡ä»¶
python main.py export --mode summary     # ç»Ÿè®¡æ‘˜è¦
python main.py export --mode readable    # æ˜“è¯»æ ¼å¼
```

#### ç”Ÿæˆçš„æ–‡ä»¶

1. **summary.json** - ç»Ÿè®¡ä¿¡æ¯
   ```json
   {
     "total": 809,
     "with_abstract": 2,
     "by_conference": {...},
     "by_download_status": {...}
   }
   ```

2. **papers_readable.json** - æ˜“è¯»æ ¼å¼
   ```json
   {
     "total": 809,
     "conferences": {
       "CRYPTO": [
         {
           "id": 1,
           "title": "...",
           "authors": ["Author1", "Author2"],
           "abstract": "...",
           "downloaded": true
         }
       ]
     }
   }
   ```

3. **all_papers.json** - å®Œæ•´æ•°æ®ï¼ˆæ‰€æœ‰å­—æ®µï¼‰

4. **{ä¼šè®®å}.json** - å„ä¼šè®®å•ç‹¬æ–‡ä»¶

### 5. å¯è§†åŒ–æŸ¥çœ‹

ä½¿ç”¨æœ¬åœ°ç½‘é¡µç•Œé¢æŸ¥çœ‹å’Œæœç´¢è®ºæ–‡ã€‚

#### å¯åŠ¨æŸ¥çœ‹å™¨

```bash
python start_viewer.py
```

æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€ http://localhost:8000/viewer.html

#### åŠŸèƒ½ç‰¹æ€§

- âœ… å®æ—¶æœç´¢ï¼ˆæ ‡é¢˜ã€ä½œè€…ï¼‰
- âœ… å¤šæ¡ä»¶ç­›é€‰ï¼ˆä¼šè®®ã€å¹´ä»½ã€çŠ¶æ€ï¼‰
- âœ… æ˜¾ç¤ºè®ºæ–‡æ‘˜è¦
- âœ… ç‚¹å‡»è®¿é—®DOIå’ŒPDFé“¾æ¥
- âœ… å¯¼å‡ºç­›é€‰ç»“æœä¸ºCSV
- âœ… å“åº”å¼è®¾è®¡

#### è§£å†³CORSé—®é¢˜

ç›´æ¥æ‰“å¼€HTMLæ–‡ä»¶ä¼šé‡åˆ°CORSé”™è¯¯ï¼Œå¿…é¡»ä½¿ç”¨æœ¬åœ°æœåŠ¡å™¨ï¼š
```bash
python start_viewer.py  # è‡ªåŠ¨å¯åŠ¨æœåŠ¡å™¨
```

---

## æ•°æ®è®¿é—®

### æ–¹å¼ä¸€ï¼šç½‘é¡µæŸ¥çœ‹å™¨ï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹ï¼š**
- å¯è§†åŒ–ç•Œé¢
- å®æ—¶æœç´¢å’Œç­›é€‰
- æ— éœ€ç¼–ç¨‹çŸ¥è¯†
- å¯¼å‡ºCSV

**ä½¿ç”¨ï¼š**
```bash
python start_viewer.py
```

### æ–¹å¼äºŒï¼šJSONæ–‡ä»¶

**ä¼˜ç‚¹ï¼š**
- æ˜æ–‡å¯è¯»
- æ˜“äºåˆ†äº«
- é€‚åˆç¼–ç¨‹å¤„ç†

**Pythonç¤ºä¾‹ï¼š**
```python
import json

with open('data/json/papers_readable.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# è·å–æ‰€æœ‰CRYPTOè®ºæ–‡
crypto_papers = data['conferences']['CRYPTO']

# æœç´¢å…³é”®è¯
keyword_papers = [p for p in crypto_papers 
                  if 'quantum' in p['title'].lower()]

# ç»Ÿè®¡æœ‰æ‘˜è¦çš„è®ºæ–‡
with_abstract = [p for p in crypto_papers if p['abstract']]
print(f"æœ‰æ‘˜è¦: {len(with_abstract)}/{len(crypto_papers)}")

# æŒ‰ä½œè€…ç­›é€‰
author_papers = [p for p in crypto_papers 
                 if any('Zhang' in a for a in p['authors'])]
```

**JavaScriptç¤ºä¾‹ï¼š**
```javascript
fetch('data/json/papers_readable.json')
  .then(response => response.json())
  .then(data => {
    const papers = data.conferences.CRYPTO;
    
    // æŸ¥æ‰¾2024å¹´çš„è®ºæ–‡
    const papers2024 = papers.filter(p => p.year === 2024);
    
    // æ˜¾ç¤º
    papers2024.forEach(p => {
      console.log(p.title);
    });
  });
```

### æ–¹å¼ä¸‰ï¼šæ•°æ®åº“æŸ¥è¯¢

**ä¼˜ç‚¹ï¼š**
- æŸ¥è¯¢é«˜æ•ˆ
- æ”¯æŒå¤æ‚æŸ¥è¯¢
- é€‚åˆå¤§è§„æ¨¡æ•°æ®

**å‘½ä»¤è¡Œå·¥å…·ï¼š**
```bash
# åˆ—å‡ºè®ºæ–‡
python query_db.py list --conference "CRYPTO" --year 2024 --limit 20

# æœç´¢
python query_db.py search "quantum cryptography"

# æ˜¾ç¤ºè¯¦æƒ…
python query_db.py detail 305

# å¯¼å‡ºCSV
python query_db.py export crypto_2024.csv --conference "CRYPTO" --year 2024

# æŸ¥çœ‹ç»Ÿè®¡
python query_db.py stats
```

**SQLæŸ¥è¯¢ï¼š**
```python
import sqlite3

conn = sqlite3.connect('data/papers.db')
cursor = conn.cursor()

# æŸ¥è¯¢ç¤ºä¾‹
cursor.execute("""
    SELECT title, authors, year 
    FROM papers 
    WHERE conference = 'CRYPTO' 
      AND year >= 2020
      AND abstract IS NOT NULL
    ORDER BY year DESC
""")

for row in cursor.fetchall():
    print(row)

conn.close()
```

**å¤æ‚æŸ¥è¯¢ç¤ºä¾‹ï¼š**
```sql
-- ç»Ÿè®¡å„å¹´ä»½è®ºæ–‡æ•°
SELECT year, COUNT(*) as count
FROM papers
GROUP BY year
ORDER BY year DESC;

-- æŸ¥æ‰¾ç‰¹å®šä½œè€…çš„æ‰€æœ‰è®ºæ–‡
SELECT title, conference, year
FROM papers
WHERE authors LIKE '%Zhang%'
ORDER BY year DESC;

-- ç»Ÿè®¡æœ‰æ‘˜è¦çš„æ¯”ä¾‹
SELECT 
    conference,
    COUNT(*) as total,
    SUM(CASE WHEN abstract IS NOT NULL THEN 1 ELSE 0 END) as with_abstract,
    ROUND(100.0 * SUM(CASE WHEN abstract IS NOT NULL THEN 1 ELSE 0 END) / COUNT(*), 2) as percentage
FROM papers
GROUP BY conference;

-- æŸ¥æ‰¾ä¸‹è½½å¤±è´¥çš„è®ºæ–‡
SELECT id, title, pdf_url
FROM papers
WHERE download_status = 'failed'
  AND pdf_url IS NOT NULL;
```

---

## é«˜çº§åŠŸèƒ½

### ä¸€é”®å®Œæˆ

æ‰§è¡Œå®Œæ•´æµç¨‹ï¼šæ”¶é›† â†’ æ‘˜è¦ â†’ ä¸‹è½½ â†’ å¯¼å‡º

```bash
python main.py all

# åŒ…å«æ‘˜è¦è·å–
python main.py all --with-abstract

# æŒ‡å®šä¼šè®®å’Œå¹´ä»½
python main.py all --conferences crypto --years 2024 --with-abstract
```

### æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯

```bash
python main.py stats
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:
  æ€»è®ºæ–‡æ•°: 809
  æŒ‰ä¼šè®®ç»Ÿè®¡:
    CRYPTO: 809
  ä¸‹è½½çŠ¶æ€:
    pending: 804
    completed: 5
============================================================
```

### æ‰¹é‡å¯¼å‡º

```python
# ä½¿ç”¨Pythonè„šæœ¬æ‰¹é‡æ“ä½œ
from utils.json_exporter import JSONExporter

exporter = JSONExporter()

# æŒ‰ä¼šè®®å¯¼å‡º
exporter.export_by_conference()

# æŒ‰å¹´ä»½å¯¼å‡º
exporter.export_by_conference_and_year()

# è‡ªå®šä¹‰å¯¼å‡º
import sqlite3
conn = sqlite3.connect('data/papers.db')
cursor = conn.cursor()

# è‡ªå®šä¹‰æŸ¥è¯¢
cursor.execute("SELECT * FROM papers WHERE year = 2024")
papers_2024 = [dict(row) for row in cursor.fetchall()]

import json
with open('custom_export.json', 'w', encoding='utf-8') as f:
    json.dump(papers_2024, f, ensure_ascii=False, indent=2)
```

### Windowså¿«é€Ÿå¯åŠ¨è„šæœ¬

```powershell
.\start.ps1
```

äº¤äº’å¼èœå•ï¼š
```
1. æ”¶é›†æ‰€æœ‰ä¼šè®®çš„è®ºæ–‡å…ƒæ•°æ®
2. æ”¶é›†ä¸‰å¤§å¯†ç å­¦ä¼šè®® (2020-2024)
3. æ”¶é›†Big4å®‰å…¨ä¼šè®® (2020-2024)
4. æ”¶é›†2024å¹´çš„æ‰€æœ‰è®ºæ–‡
5. ä¸‹è½½æ‰€æœ‰å¾…ä¸‹è½½çš„PDF
6. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
7. æ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆæ”¶é›†+ä¸‹è½½ï¼‰
8. é‡è¯•å¤±è´¥çš„ä¸‹è½½
9. è‡ªå®šä¹‰å‘½ä»¤
0. é€€å‡º
```

---

## é…ç½®è¯¦è§£

### conferences.yaml

å®šä¹‰è¦æ”¶é›†çš„ä¼šè®®ã€‚

```yaml
conferences:
  crypto:  # é…ç½®é”®
    - name: "CRYPTO"            # ä¼šè®®åç§°ï¼ˆæ˜¾ç¤ºç”¨ï¼‰
      full_name: "International Cryptology Conference"  # å…¨ç§°
      dblp_key: "conf/crypto"   # DBLPä¸­çš„é”®
      years: [2020, 2021, 2022, 2023, 2024]  # è¦æ”¶é›†çš„å¹´ä»½
      url_template: "https://..."  # ä¼šè®®å®˜ç½‘ï¼ˆé¢„ç•™ï¼‰
  
  # æ·»åŠ æ–°ä¼šè®®
  my_conference:
    - name: "MyConf"
      dblp_key: "conf/myconf"
      years: [2024]
```

**DBLP KeyæŸ¥æ‰¾ï¼š**
1. è®¿é—® https://dblp.org/
2. æœç´¢ä¼šè®®åç§°
3. æŸ¥çœ‹URLä¸­çš„è·¯å¾„ï¼Œå¦‚ `conf/crypto` å°±æ˜¯DBLP key

### settings.yaml

å…¨å±€é…ç½®å‚æ•°ã€‚

```yaml
settings:
  # æ•°æ®åº“é…ç½®
  database:
    path: "data/papers.db"
  
  # PDFå­˜å‚¨é…ç½®
  pdf_storage:
    base_path: "data/pdfs"
    organize_by: "conference"  # conference, year, or both
  
  # JSONå­˜å‚¨é…ç½®
  json_storage:
    path: "data/json"
    auto_export: true
  
  # çˆ¬è™«é…ç½®
  crawler:
    user_agent: "Mozilla/5.0 ..."
    timeout: 30          # è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
    retry_times: 3       # é‡è¯•æ¬¡æ•°
    retry_delay: 2       # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    concurrent_downloads: 3  # å¹¶å‘ä¸‹è½½æ•°
  
  # æ—¥å¿—é…ç½®
  logging:
    level: "INFO"        # DEBUG, INFO, WARNING, ERROR
    file: "logs/crawler.log"
    console: true
  
  # DBLP APIé…ç½®
  dblp:
    api_url: "https://dblp.org/search/publ/api"
    format: "json"
    max_results: 1000
```

---

## APIå‚è€ƒ

### æ•°æ®åº“API

```python
from utils.database import DatabaseManager

db = DatabaseManager('data/papers.db')

# æ’å…¥è®ºæ–‡
paper_id = db.insert_paper({
    'title': '...',
    'authors': '...',
    'year': 2024,
    'conference': 'CRYPTO',
    'doi': '...'
})

# æ›´æ–°è®ºæ–‡
db.update_paper(paper_id, {'abstract': '...'})

# æŸ¥è¯¢è®ºæ–‡
papers = db.get_papers_by_conference('CRYPTO', 2024)

# è·å–å¾…ä¸‹è½½åˆ—è¡¨
pending = db.get_pending_downloads(limit=10)

# æ›´æ–°ä¸‹è½½çŠ¶æ€
db.update_download_status(paper_id, 'completed', pdf_path='...')

# ç»Ÿè®¡ä¿¡æ¯
stats = db.get_statistics()
```

### çˆ¬è™«API

```python
from crawlers.dblp_crawler import DBLPCrawler
from crawlers.semantic_scholar_crawler import SemanticScholarCrawler

# DBLPçˆ¬è™«
dblp = DBLPCrawler(config)
papers = dblp.crawl('conf/crypto', 2024)

# Semantic Scholarçˆ¬è™«
ss = SemanticScholarCrawler(config)
info = ss.get_paper_by_doi('10.1007/...')
result = ss.search_paper_by_title('Paper Title')
```

### ä¸‹è½½å™¨API

```python
from utils.downloader import PDFDownloader

downloader = PDFDownloader(config, 'data/pdfs')

# ä¸‹è½½å•ä¸ªPDF
pdf_path = downloader.download(
    url='https://...',
    conference='CRYPTO',
    year=2024,
    filename='paper_title'
)

# æ‰¹é‡ä¸‹è½½
stats = downloader.batch_download(papers, db_manager)
```

### JSONå¯¼å‡ºAPI

```python
from utils.json_exporter import JSONExporter

exporter = JSONExporter('data/papers.db', 'data/json')

# å¯¼å‡ºæ‰€æœ‰è®ºæ–‡
exporter.export_all('output.json')

# æŒ‰ä¼šè®®å¯¼å‡º
files = exporter.export_by_conference()

# æŒ‰ä¼šè®®å’Œå¹´ä»½å¯¼å‡º
files = exporter.export_by_conference_and_year()

# å¯¼å‡ºç»Ÿè®¡
exporter.export_summary()

# æ˜“è¯»æ ¼å¼
exporter.export_readable_format()

# è‡ªåŠ¨å¯¼å‡ºæ‰€æœ‰
exporter.auto_export()
```

---

## å¸¸è§é—®é¢˜

### Q1: è®ºæ–‡æ•°é‡å¾ˆå¤šï¼Œå¦‚ä½•ä¼˜åŒ–ï¼Ÿ

**A: åˆ†æ‰¹å¤„ç†**
```bash
# æŒ‰å¹´ä»½åˆ†æ‰¹æ”¶é›†
for year in 2020 2021 2022 2023 2024; do
    python main.py collect --years $year
    python main.py export
done

# é™åˆ¶æ¯æ¬¡å¤„ç†æ•°é‡
python main.py enrich --limit 100
python main.py download --limit 50
```

### Q2: Semantic Scholar APIé€Ÿç‡é™åˆ¶ï¼Ÿ

**A: ç­–ç•¥**
- ä½¿ç”¨ `enrich_smart.py` æ™ºèƒ½è¿‡æ»¤
- è®¾ç½®è¾ƒå°çš„limit
- åˆ†å¤šæ¬¡è¿è¡Œ
- ä»£ç å·²å†…ç½®2ç§’å»¶è¿Ÿ

### Q3: PDFä¸‹è½½å¤±è´¥ï¼Ÿ

**A: æ’æŸ¥**
1. æ£€æŸ¥ `pdf_url` å­—æ®µæ˜¯å¦å­˜åœ¨
2. æŸäº›PDFéœ€è¦æœºæ„è®¿é—®æƒé™
3. ä½¿ç”¨ `python main.py retry` é‡è¯•
4. æŸ¥çœ‹æ—¥å¿— `logs/crawler.log`

### Q4: å¦‚ä½•æŸ¥çœ‹ä¸‹è½½è¿›åº¦ï¼Ÿ

**A:**
```bash
# æŸ¥çœ‹ç»Ÿè®¡
python main.py stats

# æŸ¥çœ‹æ•°æ®åº“
python query_db.py stats

# æŸ¥çœ‹JSONç»Ÿè®¡
cat data/json/summary.json
```

### Q5: å¦‚ä½•å¤‡ä»½æ•°æ®ï¼Ÿ

**A: å¤‡ä»½æ–‡ä»¶**
```bash
# æ•°æ®åº“
cp data/papers.db backup/papers_$(date +%Y%m%d).db

# JSONæ–‡ä»¶
tar -czf backup_json.tar.gz data/json/

# PDFæ–‡ä»¶
tar -czf backup_pdfs.tar.gz data/pdfs/
```

### Q6: å¦‚ä½•æ·»åŠ æ–°ä¼šè®®ï¼Ÿ

**A: ç¼–è¾‘é…ç½®**
1. åœ¨DBLPæŸ¥æ‰¾ä¼šè®®key
2. ç¼–è¾‘ `config/conferences.yaml`
3. è¿è¡Œ `python main.py collect --conferences new_conf`

### Q7: JSONæ–‡ä»¶å¤ªå¤§ï¼Ÿ

**A: ä½¿ç”¨åˆ†æ–‡ä»¶å¯¼å‡º**
```bash
# æŒ‰ä¼šè®®åˆ†æ–‡ä»¶
python main.py export --mode conference

# æŒ‰å¹´ä»½åˆ†æ–‡ä»¶
python main.py export --mode year

# æˆ–ç›´æ¥ç”¨æ•°æ®åº“æŸ¥è¯¢
python query_db.py list --conference "CRYPTO"
```

### Q8: å¦‚ä½•å¯¼å‡ºç‰¹å®šå­—æ®µï¼Ÿ

**A: è‡ªå®šä¹‰æŸ¥è¯¢**
```python
import json
import sqlite3

conn = sqlite3.connect('data/papers.db')
cursor = conn.cursor()

cursor.execute("""
    SELECT title, authors, year, doi, abstract
    FROM papers
    WHERE conference = 'CRYPTO'
""")

papers = []
for row in cursor.fetchall():
    papers.append({
        'title': row[0],
        'authors': row[1],
        'year': row[2],
        'doi': row[3],
        'abstract': row[4]
    })

with open('custom.json', 'w', encoding='utf-8') as f:
    json.dump(papers, f, ensure_ascii=False, indent=2)
```

### Q9: viewer.htmlæ˜¾ç¤ºç©ºç™½ï¼Ÿ

**A: CORSé—®é¢˜**
ä¸è¦ç›´æ¥åŒå‡»æ‰“å¼€HTMLï¼Œä½¿ç”¨ï¼š
```bash
python start_viewer.py
```

### Q10: å¦‚ä½•å®šæ—¶è‡ªåŠ¨æ›´æ–°ï¼Ÿ

**A: ä½¿ç”¨è®¡åˆ’ä»»åŠ¡**

**Windows (ä»»åŠ¡è®¡åˆ’ç¨‹åº):**
```powershell
# åˆ›å»ºæ¯å‘¨ä¸€å‡Œæ™¨2ç‚¹è¿è¡Œçš„ä»»åŠ¡
$action = New-ScheduledTaskAction -Execute "python" -Argument "C:\path\to\paper-collect\main.py all"
$trigger = New-ScheduledTaskTrigger -Weekly -DaysOfWeek Monday -At 2am
Register-ScheduledTask -TaskName "PaperCollector" -Action $action -Trigger $trigger
```

**Linux (crontab):**
```bash
# æ¯å‘¨ä¸€å‡Œæ™¨2ç‚¹è¿è¡Œ
0 2 * * 1 cd /path/to/paper-collect && python3 main.py all
```

---

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„çˆ¬è™«

åˆ›å»º `crawlers/new_crawler.py`:

```python
from crawlers.base_crawler import BaseCrawler

class NewCrawler(BaseCrawler):
    def __init__(self, config):
        super().__init__(config)
        # åˆå§‹åŒ–
    
    def crawl(self, conference, year):
        # å®ç°çˆ¬å–é€»è¾‘
        papers = []
        
        # çˆ¬å–ä»£ç 
        url = f"https://example.com/{conference}/{year}"
        response = self.fetch(url)
        
        if response:
            soup = self.parse_html(response.text)
            # è§£æHTML
            
        return papers
```

### æ‰©å±•æ•°æ®åº“å­—æ®µ

ä¿®æ”¹ `utils/database.py` ä¸­çš„è¡¨ç»“æ„ï¼š

```python
cursor.execute("""
    CREATE TABLE IF NOT EXISTS papers (
        ...
        new_field TEXT,  # æ·»åŠ æ–°å­—æ®µ
        ...
    )
""")
```

### è‡ªå®šä¹‰å¯¼å‡ºæ ¼å¼

ä¿®æ”¹ `utils/json_exporter.py`ï¼š

```python
class JSONExporter:
    def export_custom_format(self):
        # è‡ªå®šä¹‰å¯¼å‡ºé€»è¾‘
        pass
```

### æµ‹è¯•

```bash
# æµ‹è¯•æ•°æ®åº“
python -c "from utils.database import DatabaseManager; db = DatabaseManager('test.db')"

# æµ‹è¯•çˆ¬è™«
python -c "from crawlers.dblp_crawler import DBLPCrawler; c = DBLPCrawler({}); print(c.crawl('conf/crypto', 2024)[:1])"
```

### è°ƒè¯•

è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºDEBUGï¼š

`config/settings.yaml`:
```yaml
logging:
  level: "DEBUG"
```

æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼š
```bash
tail -f logs/crawler.log
```

---

## æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘ä¸‹è½½

ä¿®æ”¹ `config/settings.yaml`:
```yaml
crawler:
  concurrent_downloads: 5  # å¢åŠ å¹¶å‘æ•°
```

### æ•°æ®åº“ç´¢å¼•

å·²è‡ªåŠ¨åˆ›å»ºçš„ç´¢å¼•ï¼š
- `idx_conference_year` - æŒ‰ä¼šè®®å’Œå¹´ä»½æŸ¥è¯¢
- `idx_download_status` - æŒ‰ä¸‹è½½çŠ¶æ€æŸ¥è¯¢

æ·»åŠ æ–°ç´¢å¼•ï¼š
```python
cursor.execute("""
    CREATE INDEX idx_doi ON papers(doi)
""")
```

### ç¼“å­˜ç­–ç•¥

```python
# ä½¿ç”¨functools.lru_cacheç¼“å­˜ç»“æœ
from functools import lru_cache

@lru_cache(maxsize=100)
def expensive_operation(param):
    # è€—æ—¶æ“ä½œ
    return result
```

---

## æ•°æ®åˆ†æç¤ºä¾‹

### ç»Ÿè®¡åˆ†æ

```python
import sqlite3
import pandas as pd

conn = sqlite3.connect('data/papers.db')

# è¯»å–æ•°æ®
df = pd.read_sql_query("SELECT * FROM papers", conn)

# ç»Ÿè®¡å„ä¼šè®®è®ºæ–‡æ•°
print(df['conference'].value_counts())

# ç»Ÿè®¡å„å¹´ä»½è®ºæ–‡æ•°
print(df['year'].value_counts().sort_index())

# æœ‰æ‘˜è¦çš„æ¯”ä¾‹
abstract_ratio = df['abstract'].notna().sum() / len(df)
print(f"æœ‰æ‘˜è¦æ¯”ä¾‹: {abstract_ratio:.2%}")

# æŒ‰ä¼šè®®ç»Ÿè®¡å¹³å‡å¹´ä»½
print(df.groupby('conference')['year'].mean())

conn.close()
```

### å¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns

# è®ºæ–‡æ•°é‡è¶‹åŠ¿
df.groupby('year').size().plot(kind='line', marker='o')
plt.title('è®ºæ–‡æ•°é‡è¶‹åŠ¿')
plt.xlabel('å¹´ä»½')
plt.ylabel('è®ºæ–‡æ•°')
plt.savefig('trend.png')

# å„ä¼šè®®åˆ†å¸ƒ
df['conference'].value_counts().plot(kind='bar')
plt.title('å„ä¼šè®®è®ºæ–‡æ•°é‡')
plt.tight_layout()
plt.savefig('distribution.png')
```

---

## è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

### ä»£ç é£æ ¼

- ä½¿ç”¨Python 3.7+ç‰¹æ€§
- éµå¾ªPEP 8è§„èŒƒ
- æ·»åŠ docstringæ³¨é‡Š
- æ¨¡å—åŒ–è®¾è®¡

---

## è®¸å¯è¯

MIT License - è¯¦è§LICENSEæ–‡ä»¶

---

## è‡´è°¢

- [DBLP](https://dblp.org/) - æä¾›è®ºæ–‡å…ƒæ•°æ®
- [Semantic Scholar](https://www.semanticscholar.org/) - æä¾›è®ºæ–‡æ‘˜è¦
- æ‰€æœ‰è´¡çŒ®è€…

---

<div align="center">

**ğŸ“§ è”ç³»æ–¹å¼**

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æäº¤Issue

Made with â¤ï¸ by coperlm

</div>
